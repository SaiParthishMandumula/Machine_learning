{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96f0b049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START Q1_AB\n",
      "\n",
      "DEPTH =  1\n",
      "Accuracy  | Trainng_data =  0.84  | Test =   0.59\n",
      "DEPTH =  2\n",
      "Accuracy  | Trainng_data =  0.86  | Test =   0.59\n",
      "DEPTH =  3\n",
      "Accuracy  | Trainng_data =  0.92  | Test =   0.59\n",
      "DEPTH =  4\n",
      "Accuracy  | Trainng_data =  0.98  | Test =   0.57\n",
      "DEPTH =  5\n",
      "Accuracy  | Trainng_data =  0.98  | Test =   0.57\n",
      "END Q1_AB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "extent = 0\n",
    "mi_share = 2\n",
    "\n",
    "\n",
    "class make_decision_tree():# for the class which make the decision tree to create.\n",
    "    def __init__(Inuse, miShares=mi_share, max_depth=extent):\n",
    "        Inuse.root = None # if the node has the null value.\n",
    "# for stopping the condition statements.\n",
    "        Inuse.miShares = miShares #if inuse.mishars then mishare is  declare.\n",
    "        Inuse.max_depth = max_depth # if the function = max_depth value.\n",
    "def calculate_Accuracy(E_Actual, E_Estimate, normalize=True): # it will calculate Accuracy of actual and estimated value ..\n",
    "    Accuracy = [] #we  create variable for the null value .\n",
    "    for i in range(len(E_Estimate)): # for every value in the range .\n",
    "        if E_Estimate[i] == E_Actual[i]: #if Estimation is the actual value.\n",
    "            Accuracy.append(1)\n",
    "        else:\n",
    "            Accuracy.append(0)\n",
    "\n",
    "    return np.round(np.mean(Accuracy), decimals=2)\n",
    "\n",
    "\n",
    "class St():\n",
    "    def __init__(Inuse, Unknown_inde=None, Highestlimit=None, left=None, right=None, Information_Profit=None, Coast=None):\n",
    "        #  it will constructor  for  the decision to split  into  left slave and right slave.\n",
    "        # for contruction for the decision node\n",
    "        Inuse.Unknown_inde = Unknown_inde\n",
    "        Inuse.Highestlimit=Highestlimit\n",
    "        Inuse.left = left # for the inuse to move to left\n",
    "        Inuse.right = right #for the inuse node to move to right.\n",
    "        Inuse.Information_Profit = Information_Profit # inuse we met the profit\n",
    "        # for the leaf node to  build.\n",
    "        Inuse.Coast= Coast # the present inuse value is equalize or initialize to the coast.\n",
    "\n",
    "\n",
    "class make_decision_tree(): # for the decision tree to make.\n",
    "    def __init__(Inuse, miShares=mi_share, max_depth=extent): # for the init where the extent.\n",
    "        Inuse.root = None # if there is any  null value are present.\n",
    "        #  for the stoping conditions.\n",
    "        Inuse.miShares = miShares # for the splits.\n",
    "        Inuse.max_depth = max_depth\n",
    "\n",
    "    def build_tree(Autonoic, Infoset, curr_depth=0):\n",
    "        #   for the recursion to run for the particular time.\n",
    "        X, E = Infoset[:, :-1], Infoset[:, -1] # for the X,e there is inforest  and the step function is -1\n",
    "        number_demos, num_Unknown = np.shape(X) # for the number_demos and the np_shapes  of the variable x\n",
    "\n",
    "        # it will share  until the all the conditions are met and satisfied it  will go on .\n",
    "        if number_demos >= Autonoic.miShares and curr_depth <= Autonoic.max_depth:\n",
    "            #  it will find  the best possible way to share the data.\n",
    "            Best_Shares = Autonoic.get_Best_Shares(\n",
    "                Infoset, number_demos, num_Unknown)\n",
    "            #  it will run the program and check if it is positive..\n",
    "            if Best_Shares[\"Information_Profit\"] > 0:\n",
    "                #  it will make to move the recursion to the leftside of the desicion tree.\n",
    "                left_subtree = Autonoic.build_tree(\n",
    "                    Best_Shares[\"Infoset_left\"], curr_depth+1)\n",
    "                # it will shift the recursion to it right side ..\n",
    "                right_subtree = Autonoic.build_tree(\n",
    "                    Best_Shares[\"Infoset_right\"], curr_depth+1)\n",
    "                # it will hleps to know the decision node value of the given data.\n",
    "                return St(Best_Shares[\"Unknown_inde\"], Best_Shares[\"Highestlimit\"],\n",
    "                             left_subtree, right_subtree, Best_Shares[\"Information_Profit\"])\n",
    "\n",
    "        # when the data got split it will help the best share to split the data to its leftnode.\n",
    "        leaf_Coast = Autonoic.calculate_leaf_Coast(E)\n",
    "        # it will help the left node value to return..\n",
    "        return St(Coast=leaf_Coast)\n",
    "\n",
    "    def get_Best_Shares(Autonoic, Infoset, number_demos, num_Unknown):\n",
    "        # we write this function to create for the best leftnode or thr right node.\n",
    "\n",
    "        #  when the data is split we need to store the data value or the data infomation..\n",
    "        Best_Shares = {}\n",
    "        max_Information_Profit = -float(\"inf\")\n",
    "\n",
    "        # here it will loop over all the features.\n",
    "        for Unknown_inde in range(num_Unknown):\n",
    "            Unknown_Coasts = Infoset[:, Unknown_inde]\n",
    "            possible_Highestlimits = np.unique(Unknown_Coasts)\n",
    "            # it will create the loop for the future data ..\n",
    "            for Highestlimit in possible_Highestlimits:\n",
    "                # when the dataset it will need to get current split.\n",
    "                Infoset_left, Infoset_right = Autonoic.split(\n",
    "                    Infoset, Unknown_inde, Highestlimit)\n",
    "                # we need to make sure that slaves are not null values.\n",
    "                if len(Infoset_left) > 0 and len(Infoset_right) > 0:\n",
    "                    E, left_E, right_E = Infoset[:, -\n",
    "                                                 1], Infoset_left[:, -1], Infoset_right[:, -1]\n",
    "                    # it need to compute the information \n",
    "                    curr_Information_Profit = Autonoic.information_Achieved(\n",
    "                        E, left_E, right_E)\n",
    "                    # if there is any future best split  for the given_dataset it will update the value.\n",
    "                    if curr_Information_Profit > max_Information_Profit:\n",
    "                        Best_Shares[\"Unknown_inde\"] = Unknown_inde # unknown inde for the unknow value . \n",
    "                        Best_Shares[\"Highestlimit\"] = Highestlimit \n",
    "                        Best_Shares[\"Infoset_left\"] = Infoset_left\n",
    "                        Best_Shares[\"Infoset_right\"] = Infoset_right\n",
    "                        Best_Shares[\"Information_Profit\"] = curr_Information_Profit\n",
    "                        max_Information_Profit = curr_Information_Profit\n",
    "\n",
    "        # when the bestsplit is  done  it will return the best return value.\n",
    "        return Best_Shares\n",
    "\n",
    "    def split(Autonoic, Infoset, Unknown_inde, Highestlimit):\n",
    "        #  the function that to  share the data.\n",
    "\n",
    "        Infoset_left = np.array(\n",
    "            [queue for queue in Infoset if queue[Unknown_inde] <= Highestlimit])\n",
    "        Infoset_right = np.array(\n",
    "            [queue for queue in Infoset if queue[Unknown_inde] > Highestlimit])\n",
    "        return Infoset_left, Infoset_right\n",
    "\n",
    "    def information_Achieved(Autonoic, Master, l_Slave, r_Slave):\n",
    "        #  we need a function  to get achieved so that the automatic ,master, l_slave vlaue and r_slave value is done..\n",
    "\n",
    "        Load_l = len(l_Slave) / len(Master)\n",
    "        Load_r = len(r_Slave) / len(Master)\n",
    "        Achieved = Autonoic.entropy(\n",
    "            Master) - (Load_l*Autonoic.entropy(l_Slave) + Load_r*Autonoic.entropy(r_Slave))\n",
    "        return Achieved\n",
    "\n",
    "    def entropy(Autonoic, E):\n",
    "        #  a function value is used  to compute the entropy.\n",
    "        class_labels = np.unique(E)\n",
    "        entropy = 0\n",
    "        for clse in class_labels:\n",
    "            p_clse = len(E[E == clse]) / len(E)\n",
    "            entropy += -p_clse * np.log2(p_clse) # By using in-bilt log function will calculate entropy\n",
    "        return entropy\n",
    "\n",
    "    def calculate_leaf_Coast(Autonoic, E):\n",
    "        #  in the decision tree we need a leaf node or slave node it will compute to create a leaf-node.\n",
    "\n",
    "        E = list(E)\n",
    "        return max(E, key=E.count)\n",
    "\n",
    "    \n",
    "\n",
    "    def fit(Autonoic, X, E):\n",
    "        #   when the dataset is split we need  train the decision tree   get the accuracy  of the test and the train value.\n",
    "\n",
    "        Infoset= np.concatenate((X, E), axis=1)\n",
    "        Autonoic.root =Autonoic.build_tree(Infoset)\n",
    "\n",
    "    def predictor_function(Autonoic, X):\n",
    "        # for the  newdata to begin or compute we define a function.\n",
    "\n",
    "        preditions = [Autonoic.make_prediction(x, Autonoic.root) for x in X]\n",
    "        return preditions\n",
    "\n",
    "    def make_prediction(Autonoic, x, tree):\n",
    "        #  when there is a single datapoint x we need a function to do..\n",
    "\n",
    "        if tree.Coast != None:\n",
    "            return tree.Coast\n",
    "        Unknown_val = x[tree.Unknown_inde]\n",
    "        if Unknown_val <= tree.Highestlimit:\n",
    "            return Autonoic.make_prediction(x, tree.left)\n",
    "        else:\n",
    "            return Autonoic.make_prediction(x, tree.right)\n",
    "\n",
    "def file_reader(track):\n",
    "    #Getting the file information\n",
    "    informationcontain_file = open(track)\n",
    "    channel = informationcontain_file.readline() \n",
    "    knowledge = []\n",
    "    while channel:\n",
    "        channel = channel.rstrip()\n",
    "        knowledge.append(channel)\n",
    "        channel = informationcontain_file.readline()\n",
    "        Sol = []\n",
    "    #intializing the traing data as empty array\n",
    "    Trainng_data = []\n",
    "    for queue in knowledge:\n",
    "        u = \"\"\n",
    "        for fg in queue:\n",
    "            if (fg == '(' or fg == ')' or fg == ' '):\n",
    "                continue\n",
    "            else:\n",
    "                u += fg\n",
    "        d = u.split(',')\n",
    "        Trainng_data.append(d)\n",
    "\n",
    "    for queue in Trainng_data:\n",
    "        mortal= []\n",
    "        #Appending the data to the mortal variable\n",
    "        mortal.append(float(queue[0]))\n",
    "        mortal.append(float(queue[1]))\n",
    "        mortal.append(int(queue[2]))\n",
    "        \n",
    "        mortal2 = []\n",
    "        mortal2.append(mortal)\n",
    "        [[mortal],]\n",
    "        if (queue[3] == 'M'):\n",
    "            mortal2.append([1])\n",
    "        else:\n",
    "            mortal2.append([0])\n",
    "\n",
    "        Sol.append(mortal2)\n",
    "    return Sol\n",
    "def main():\n",
    "    print('START Q1_AB\\n')\n",
    "\n",
    "    # Taking the dataset\n",
    "    X_Trainng_data = []\n",
    "    X_test = []\n",
    "    E_Trainng_data = []\n",
    "    E_test = []\n",
    "\n",
    "    Trainng_data = file_reader('datasets/Q1_train.txt') # reading the train data\n",
    "    test_knowledge = file_reader('datasets/Q1_test.txt') # reading the test data\n",
    "\n",
    "    len_Trainng_data= len(Trainng_data)\n",
    "    for i in Trainng_data:\n",
    "        X_Trainng_data.append(i[0])\n",
    "        E_Trainng_data.append(i[1])\n",
    "\n",
    "    len_test = len(test_knowledge)\n",
    "    for i in test_knowledge:\n",
    "        X_test.append(i[0])\n",
    "        E_test.append(i[1])\n",
    "\n",
    "    mi_share = 3\n",
    "    extent = 1\n",
    "\n",
    "    for i in range(5):\n",
    "        # classifer is called here.\n",
    "        classifier = make_decision_tree(  # Calling the decision tree calssifier\n",
    "            miShares=mi_share, max_depth=extent)\n",
    "        classifier.fit(X_Trainng_data, E_Trainng_data)\n",
    "\n",
    "        print(\"DEPTH = \", extent) # Printing the depth of it\n",
    "        E_Trainng_data_Estimate = classifier.predictor_function(X_Trainng_data) # Estimating the traing data value\n",
    "        Trainng_data_Accuracy = calculate_Accuracy(E_Trainng_data, E_Trainng_data_Estimate)\n",
    "\n",
    "        E_test_Estimate = classifier.predictor_function(X_test) # Estimating the test data value\n",
    "        test_Accuracy = calculate_Accuracy(E_test, E_test_Estimate)\n",
    "        # Finding the accuracy of train and test data\n",
    "        print(\"Accuracy  | Trainng_data = \", Trainng_data_Accuracy, \n",
    "              \" | Test =  \", test_Accuracy)\n",
    "        extent = extent + 1\n",
    "\n",
    "    print('END Q1_AB\\n')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eeb5f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
